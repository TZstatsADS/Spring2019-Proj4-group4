mean_ratio = kickstart %>% group_by(top_category) %>% sum(achievement_ratio)
mean_ratio = kickstart %>% group_by(top_category) %>%
mean(achievement_ratio)
kickstart$achievement_ratio = (kickstart$pledged/kickstart$goal)*100
kickstart$achievement_ratio
mean_ratio = kickstart %>% group_by(top_category) %>%
mean(achievement_ratio)
class(kickstart$achievement_ratio)
kickstart$achievement_ratio
mean_ratio = kickstart %>% group_by(top_category) %>%
sum(achievement_ratio)
mean_ratio = kickstart %>% group_by(top_category) %>%
count()
mean_ratio
kickstart = read.csv("kickstarter_projects.csv")
mean_ratio = kickstart %>% group_by(top_category) %>%
mean(achieve_ratio)
sum(is.na(kickstart$achieve_ratio))
kickstart$achieve_ratio
colnames(kickstart)
kickstart = kickstart[!is.na(kickstart$goal),]
kickstart$achieve_ratio = (kickstart$pledged/kickstart$goal)*100
mean_ratio = kickstart %>% group_by(top_category) %>%
mean(achieve_ratio)
kickstart$achieve_ratio
sum(is.na(kickstart$achieve_ratio))
is.na(kickstart$achieve_ratio
is.na(kickstart$achieve_ratio)
is.na(kickstart$achieve_ratio)
mean_ratio = kickstart %>% group_by(top_category) %>%
sum(achieve_ratio)
mean_ratio = kickstart %>% group_by(top_category) %>%
sum(achieve_ratio)
kickstart$achieve_ratio
sum(is.na(kickstart$achieve_ratio))
mean_ratio = kickstart %>% group_by(top_category) %>%
summarise(sum(achieve_ratio))
mean_ratio
mean_ratio = kickstart %>% group_by(top_category) %>%
summarise(mean(achieve_ratio))
mean_ratio
mean_ratio = kickstart %>% group_by(top_category) %>%
summarise(mean_ratio = mean(achieve_ratio))
mean_ratio
mean_ratio = kickstart %>% group_by(top_category) %>%
summarise(mean_ratio = mean(achieve_ratio)) %>%
arrange(desc(achieve_ratio))
mean_ratio = kickstart %>% group_by(top_category) %>%
summarise(mean_ratio = mean(achieve_ratio)) %>%
arrange(desc(mean_ratio))
mean_ratio
library(knitr)
opts_chunk$set(fig.path="figures/",
cache.path="cache/",
cache=FALSE,
echo=TRUE,
message=FALSE,
warning=FALSE)
athletes_events = read.csv("athletes_and_events.csv")
athletes_events = read.csv("athletes_and_events.csv")
library(tidyr)
library(plyr)
library(tidyverse)
library(tidyverse)
library(dplyr)
library(ggplot2)
athletes_events = read.csv("athletes_and_events.csv")
kickstart %>% group_by(top_category, state) %>% count()
colnames(kickstart)
kickstart %>% group_by(top_category, state) %>% n()
kickstart %>% group_by(top_category, state) %>% count()
success = kickstart %>% group_by(top_category, state) %>% count()
success
success = kickstart %>% group_by(top_category, state) %>%
summarise(count = n())
colnames(kickstart)
success = kickstart %>% group_by(state) %>%
summarise(count = n())
success = kickstart %>% group_by(state) %>% count()
success = kickstart %>% group_by(state) %>% count()
success
success = kickstart %>% group_by(state) %>% summarise(count = n())
success
success = kickstart %>% group_by(top_category) %>% summarise(count = n())
success = kickstart %>% group_by(top_category) %>% count()
success
# install.packages('dplyr')
library(dplyr)
success = kickstart %>% group_by(top_category) %>% count()
success
kickstart$state
success = kickstart %>% group_by(top_category) %>% summarise(mean(achieve_ratio))
success
kickstart = kickstart[!is.na(kickstart$goal),]
kickstart$achieve_ratio = (kickstart$pledged/kickstart$goal)*100
mean_ratio = kickstart %>% group_by(top_category) %>%
summarise(mean_ratio = mean(achieve_ratio)) %>%
arrange(desc(mean_ratio))
mean_ratio
install.packages('dplyr')
library(dplyr)
install.packages("dplyr")
library(knitr)
opts_chunk$set(fig.path="figures/",
cache.path="cache/",
cache=FALSE,
echo=TRUE,
message=FALSE,
warning=FALSE)
library(dplyr)
kickstart = read.csv("kickstarter_projects.csv")
kickstart = kickstart[!is.na(kickstart$goal),]
kickstart$achieve_ratio = (kickstart$pledged/kickstart$goal)*100
mean_ratio = kickstart %>% group_by(top_category) %>%
summarise(mean_ratio = mean(achieve_ratio)) %>%
arrange(desc(mean_ratio))
mean_ratio
success = kickstart %>% group_by(top_category) %>% summarise(mean(achieve_ratio))
success
success = kickstart %>% group_by(state, top_category) %>% count()
success
colnames(kickstart)
success
success = kickstart %>% group_by(top_category, state) %>% count()
success
success = kickstart %>% group_by(top_category) %>%
summarize(success_rate = sum(state=='successful')/count())
success = kickstart %>% group_by(top_category) %>%
summarize(success_rate = sum(state=='successful')/count(n))
success = kickstart %>% group_by(top_category) %>%
summarize(success_rate = sum(state=='successful')/count())
success = kickstart %>% group_by(top_category) %>%
summarize(success_rate = sum(state=='successful'))
success
success = kickstart %>% group_by(top_category) %>%
summarize(success_rate = sum(state=='successful')/n())
success
success = kickstart %>% group_by(top_category) %>%
summarize(success_rate = sum(state=='successful')/n()(100))
success = kickstart %>% group_by(top_category) %>%
summarize(success_rate = sum(state=='successful')/n()*(100))
success
success = kickstart %>% group_by(top_category) %>%
summarize(success_rate = sum(state=='successful')/n()*100)
success
success = kickstart %>% group_by(top_category) %>%
summarize(success_rate = sum(state=='successful')/n()*100) %>%
arrange(desc(success_rate))
success
ggplot(success, aes(x=top_category, y=success_rate)) +
geom_bar(stat = 'identity', fill='steelblue')
library(ggplot)
library(ggplot2)
ggplot(success, aes(x=top_category, y=success_rate)) +
geom_bar(stat = 'identity', fill='steelblue')
ggplot(success, aes(x=top_category, y=reorder(success_rate))) +
geom_bar(stat = 'identity', fill='steelblue')
ggplot(success, aes(x=reorder(top_category, success_rate), y=success_rate) +
ggplot(success, aes(x=reorder(top_category, success_rate), y=success_rate)) +
geom_bar(stat = 'identity', fill='steelblue')
ggplot(success, aes(x=reorder(top_category, success_rate), y=success_rate)) +
ggplot(success, aes(x=reorder(top_category, success_rate), y=success_rate)) +
geom_bar(stat='identity', fill='steelblue')
ggplot(success, aes(y=reorder(top_category, success_rate), x=success_rate)) +
geom_bar(stat='identity', fill='steelblue')
ggplot(success, aes(x=success_rate, y=reorder(top_category, success_rate))) +
geom_bar(stat='identity', fill='steelblue')
p1 + theme(axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(hjust = 0.5)) +
ggtitle("Success Rate by Category")
p1 = ggplot(success, aes(x=reorder(top_category, success_rate), y=success_rate)) +
geom_bar(stat='identity', fill='steelblue')
p1 + theme(axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(hjust = 0.5)) +
ggtitle("Success Rate by Category")
p1 + theme(axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(hjust = 0.5)) +
ggtitle("Success Rate by Category") +
labs(x="Category", y='Success Rate')
token = "Wrldfoooiaehr70).'"
strsplit(token,"")
strsplit(token,"")[[1]]
bigram <- function(token){
## Split into characterss:
w <- strsplit(token, "")[[1]]
## Word tri-grams pasted together:
return(vapply(ngrams(w, 2L), paste, "", collapse = ""))
}
bigram(token)
bigram <- function(token){
## Split into characterss:
w <- strsplit(token, "")[[1]]
## Word tri-grams pasted together:
return(vapply(ngrams(w, 2L), paste, "", collapse = ""))
}
token = "Wrldfoooiaehr70).'"
bigram <- function(token){
## Split into characterss:
w <- strsplit(token, "")[[1]]
## Word tri-grams pasted together:
return(vapply(ngrams(w, 2L), paste, "", collapse = ""))
}
bigram(token = token)
bigram(token = token)
install.packages("ngram")
library(ngram)
token = "Wrldfoooiaehr70).'"
bigram <- function(token){
## Split into characterss:
w <- strsplit(token, "")[[1]]
## Word tri-grams pasted together:
return(vapply(ngrams(w, 2L), paste, "", collapse = ""))
}
bigram(token = token)
install.packages("quanteda")
install.packages("NLP")
library(NLP)
token = "Wrldfoooiaehr70).'"
bigram <- function(token){
## Split into characterss:
w <- strsplit(token, "")[[1]]
## Word tri-grams pasted together:
return(vapply(ngrams(w, 2L), paste, "", collapse = ""))
}
bigram(token = token)
ngrams(token, 2L)
vapply(ngrams(token, 2L))
vapply(ngrams(token, 2L), paste, "")
vapply(ngrams(token, 2L), paste, "", collapse = "")
token = "Wrldfoooiaehr70).'"
vapply(ngrams(token, 2L), paste, "", collapse = "")
?ngrams
findfeatures <- function(token){
features <- list()
#### feature 1
l <- nchar(token)
features[[1]] <- l
#### feature 2
vowel <- "[aeiouAEIOU]" # vowels
consonants <- "[bcdfghjklmnpqrstvwxyzBCDFGHJKLMNPQRSTVWXYZ]" # consonants
v <- str_count(token, pattern = vowel) # number of vowels
c <- str_count(token, pattern = consonants) # number of consonants
features[[2]] <- c(v/l, c/l, v/c)
### feature 3
ln <- "[:alnum:]" # letters and numbers
s <- l - str_count(token, pattern = ln)
features[[3]] <- s/l
### feature 4
digit <- "[:digit:]"
d <- str_count(token, pattern = digit)
features[[4]] <- d/l
### feature 5
upr <- "[:upper:]"
lwr <- "[:lower:]"
upp <- str_count(token, pattern = upr)
low <- str_count(token, pattern = lwr)
features[[5]] <- c(low/l, upp/l)
### feature 6
letters <- strsplit(token, "")[[1]]
run_length <- max(rle(letters)$length)
m <- ifelse(run_length >= 3, run_length/l,0)
features[[6]] <- m
### feature 7
la <- str_count(token, pattern = ln)
features[[7]] <- ifelse(s > la, 1,0) # k = s
### feature 8
c_token <- gsub(consonants, "c", token) # replace the consonants with letter c
c_split <- strsplit(c_token, "")[[1]]
c_run_length <- max(rle(c_split)$length)
features[[8]] <- ifelse(c_run_length >=6, 1,0)
### feature 9
infix <- substr(token, start = 2, stop = nchar(token)-1)
n <- l - str_count(infix, ln)
features[[9]] <- ifelse(n >= 2, 1,0)
### feature 10 -- Bigram
nums <- nchar(token)-1
bigr <- tolower(bigram(token)) # change into lowercase
features[[10]] <- (sum(unlist(lapply(bigr, freq_bigr, LB)))/10000)/nums
### return features
return(unlist(features))
}
findfeatures <- function(token){
features <- list()
#### feature 1
l <- nchar(token)
features[[1]] <- l
#### feature 2
vowel <- "[aeiouAEIOU]" # vowels
consonants <- "[bcdfghjklmnpqrstvwxyzBCDFGHJKLMNPQRSTVWXYZ]" # consonants
v <- str_count(token, pattern = vowel) # number of vowels
c <- str_count(token, pattern = consonants) # number of consonants
features[[2]] <- c(v/l, c/l, v/c)
### feature 3
ln <- "[:alnum:]" # letters and numbers
s <- l - str_count(token, pattern = ln)
features[[3]] <- s/l
### feature 4
digit <- "[:digit:]"
d <- str_count(token, pattern = digit)
features[[4]] <- d/l
### feature 5
upr <- "[:upper:]"
lwr <- "[:lower:]"
upp <- str_count(token, pattern = upr)
low <- str_count(token, pattern = lwr)
features[[5]] <- c(low/l, upp/l)
### feature 6
letters <- strsplit(token, "")[[1]]
run_length <- max(rle(letters)$length)
m <- ifelse(run_length >= 3, run_length/l,0)
features[[6]] <- m
### feature 7
la <- str_count(token, pattern = ln)
features[[7]] <- ifelse(s > la, 1,0) # k = s
### feature 8
c_token <- gsub(consonants, "c", token) # replace the consonants with letter c
c_split <- strsplit(c_token, "")[[1]]
c_run_length <- max(rle(c_split)$length)
features[[8]] <- ifelse(c_run_length >=6, 1,0)
### feature 9
infix <- substr(token, start = 2, stop = nchar(token)-1)
n <- l - str_count(infix, ln)
features[[9]] <- ifelse(n >= 2, 1,0)
### feature 10 -- Bigram
nums <- nchar(token)-1
bigr <- tolower(bigram(token)) # change into lowercase
features[[10]] <- (sum(unlist(lapply(bigr, freq_bigr, LB)))/10000)/nums
### return features
return(unlist(features))
}
findfeatures(token)
install.packages("stringr")
library(stringr)
findfeatures <- function(token){
features <- list()
#### feature 1
l <- nchar(token)
features[[1]] <- l
#### feature 2
vowel <- "[aeiouAEIOU]" # vowels
consonants <- "[bcdfghjklmnpqrstvwxyzBCDFGHJKLMNPQRSTVWXYZ]" # consonants
v <- str_count(token, pattern = vowel) # number of vowels
c <- str_count(token, pattern = consonants) # number of consonants
features[[2]] <- c(v/l, c/l, v/c)
### feature 3
ln <- "[:alnum:]" # letters and numbers
s <- l - str_count(token, pattern = ln)
features[[3]] <- s/l
### feature 4
digit <- "[:digit:]"
d <- str_count(token, pattern = digit)
features[[4]] <- d/l
### feature 5
upr <- "[:upper:]"
lwr <- "[:lower:]"
upp <- str_count(token, pattern = upr)
low <- str_count(token, pattern = lwr)
features[[5]] <- c(low/l, upp/l)
### feature 6
letters <- strsplit(token, "")[[1]]
run_length <- max(rle(letters)$length)
m <- ifelse(run_length >= 3, run_length/l,0)
features[[6]] <- m
### feature 7
la <- str_count(token, pattern = ln)
features[[7]] <- ifelse(s > la, 1,0) # k = s
### feature 8
c_token <- gsub(consonants, "c", token) # replace the consonants with letter c
c_split <- strsplit(c_token, "")[[1]]
c_run_length <- max(rle(c_split)$length)
features[[8]] <- ifelse(c_run_length >=6, 1,0)
### feature 9
infix <- substr(token, start = 2, stop = nchar(token)-1)
n <- l - str_count(infix, ln)
features[[9]] <- ifelse(n >= 2, 1,0)
### feature 10 -- Bigram
nums <- nchar(token)-1
bigr <- tolower(bigram(token)) # change into lowercase
features[[10]] <- (sum(unlist(lapply(bigr, freq_bigr, LB)))/10000)/nums
### return features
return(unlist(features))
}
findfeatures(token)
library(NLP)
library(stringr)
findfeatures <- function(token){
features <- list()
#### feature 1
l <- nchar(token)
features[[1]] <- l
#### feature 2
vowel <- "[aeiouAEIOU]" # vowels
consonants <- "[bcdfghjklmnpqrstvwxyzBCDFGHJKLMNPQRSTVWXYZ]" # consonants
v <- str_count(token, pattern = vowel) # number of vowels
c <- str_count(token, pattern = consonants) # number of consonants
features[[2]] <- c(v/l, c/l, v/c)
### feature 3
ln <- "[:alnum:]" # letters and numbers
s <- l - str_count(token, pattern = ln)
features[[3]] <- s/l
### feature 4
digit <- "[:digit:]"
d <- str_count(token, pattern = digit)
features[[4]] <- d/l
### feature 5
upr <- "[:upper:]"
lwr <- "[:lower:]"
upp <- str_count(token, pattern = upr)
low <- str_count(token, pattern = lwr)
features[[5]] <- c(low/l, upp/l)
### feature 6
letters <- strsplit(token, "")[[1]]
run_length <- max(rle(letters)$length)
m <- ifelse(run_length >= 3, run_length/l,0)
features[[6]] <- m
### feature 7
la <- str_count(token, pattern = ln)
features[[7]] <- ifelse(s > la, 1,0) # k = s
### feature 8
c_token <- gsub(consonants, "c", token) # replace the consonants with letter c
c_split <- strsplit(c_token, "")[[1]]
c_run_length <- max(rle(c_split)$length)
features[[8]] <- ifelse(c_run_length >=6, 1,0)
### feature 9
infix <- substr(token, start = 2, stop = nchar(token)-1)
n <- l - str_count(infix, ln)
features[[9]] <- ifelse(n >= 2, 1,0)
### feature 10 -- Bigram
nums <- nchar(token)-1
bigr <- tolower(bigram(token)) # change into lowercase
features[[10]] <- (sum(unlist(lapply(bigr, freq_bigr, LB)))/10000)/nums
### return features
return(unlist(features))
}
findfeatures(token)
findfeatures <- function(token){
features <- list()
#### feature 1
l <- nchar(token)
features[[1]] <- l
#### feature 2
vowel <- "[aeiouAEIOU]" # vowels
consonants <- "[bcdfghjklmnpqrstvwxyzBCDFGHJKLMNPQRSTVWXYZ]" # consonants
v <- str_count(token, pattern = vowel) # number of vowels
c <- str_count(token, pattern = consonants) # number of consonants
features[[2]] <- c(v/l, c/l, v/c)
### feature 3
ln <- "[:alnum:]" # letters and numbers
s <- l - str_count(token, pattern = ln)
features[[3]] <- s/l
### feature 4
digit <- "[:digit:]"
d <- str_count(token, pattern = digit)
features[[4]] <- d/l
### feature 5
upr <- "[:upper:]"
lwr <- "[:lower:]"
upp <- str_count(token, pattern = upr)
low <- str_count(token, pattern = lwr)
features[[5]] <- c(low/l, upp/l)
### feature 6
letters <- strsplit(token, "")[[1]]
run_length <- max(rle(letters)$length)
m <- ifelse(run_length >= 3, run_length/l,0)
features[[6]] <- m
### feature 7
la <- str_count(token, pattern = ln)
features[[7]] <- ifelse(s > la, 1,0) # k = s
### feature 8
c_token <- gsub(consonants, "c", token) # replace the consonants with letter c
c_split <- strsplit(c_token, "")[[1]]
c_run_length <- max(rle(c_split)$length)
features[[8]] <- ifelse(c_run_length >=6, 1,0)
### feature 9
infix <- substr(token, start = 2, stop = nchar(token)-1)
n <- l - str_count(infix, ln)
features[[9]] <- ifelse(n >= 2, 1,0)
# ### feature 10 -- Bigram
# nums <- nchar(token)-1
# bigr <- tolower(bigram(token)) # change into lowercase
# features[[10]] <- (sum(unlist(lapply(bigr, freq_bigr, LB)))/10000)/nums
### return features
return(unlist(features))
}
findfeatures(token)
tokens = read.csv("../output/ocr_output.csv")
tokens = read.csv("./output/ocr_output.csv")
tokens = read.csv("~/output/ocr_output.csv")
tokens = read.csv("..~/output/ocr_output.csv")
tokens = read.csv("~../output/ocr_output.csv")
setwd("~/Documents/Spring2019/ADS/Spring2019-Proj4-group4/lib")
tokens = read.csv("../output/ocr_output.csv")
View(tokens)
tok_labels = read.csv("../output/ocr_output.csv")
source("features.R")
install.packages("NLP")
install.packages("stringr")
tok_label = read.csv("../output/ocr_output.csv")
tokens = tok_labels$tokens
tokens = tok_label$tokens
labels = tok_label$labels
dim(tokens)
tokens = tok_label$tokens
labels = tok_label$labels
class(tokens)
tokens
as.character(tokens)
tokens = as.character(tok_label$tokens)
tokens
class(tokens)
length(tokens)
tokens[1]
